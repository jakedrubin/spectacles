{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dcd166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HOME\"] = os.path.expanduser(\"~\")\n",
    "\n",
    "# Read Clarifai API key from environment. Export CLARIFAI_API_KEY before running this notebook.\n",
    "CLARIFAI_API_KEY = os.environ.get('CLARIFAI_API_KEY')\n",
    "if not CLARIFAI_API_KEY:\n",
    "    print(\"Warning: CLARIFAI_API_KEY not set in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a7cb7",
   "metadata": {},
   "source": [
    "# Make data\n",
    "\n",
    "this part takes the facial data points from SCUT and makes face_measurements.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df48e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract facial geometry from SCUT-FBP5500 landmarks in .pts format\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "\n",
    "# === Helper: Euclidean distance ===\n",
    "def distance(p1, p2):\n",
    "    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "# === Parse .pts landmark file with encoding fallback ===\n",
    "def parse_pts(filepath):\n",
    "    import numpy as np\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            raw = f.read()\n",
    "        float_data = np.frombuffer(raw, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Binary load failed: {e}\")\n",
    "\n",
    "    if len(float_data) != 173:\n",
    "        raise ValueError(f\"Unexpected float count: {len(float_data)}\")\n",
    "\n",
    "    coords = float_data[1:]  # skip first float (junk/header)\n",
    "    landmarks = list(zip(coords[::2], coords[1::2]))  # (x, y) pairs\n",
    "    return landmarks\n",
    "\n",
    "# === Extract facial metrics ===\n",
    "def compute_metrics(landmarks):\n",
    "    chin = landmarks[55]         # bottom of chin\n",
    "    forehead = landmarks[19]     # top center\n",
    "    jaw_left = landmarks[0]      # left jaw corner\n",
    "    jaw_right = landmarks[10]    # right jaw corner\n",
    "    eye_left = landmarks[37]     # left pupil center\n",
    "    eye_right = landmarks[46]    # right pupil center\n",
    "\n",
    "    width = distance(jaw_left, jaw_right)\n",
    "    height = distance(forehead, chin)\n",
    "    eye_spacing = distance(eye_left, eye_right)\n",
    "    ratio = width / height if height else 0\n",
    "\n",
    "    return width, height, ratio, eye_spacing\n",
    "\n",
    "# === Main loop ===\n",
    "landmark_dir = \"SCUT-FBP5500/landmarks\"  # Update path as needed\n",
    "output_csv = \"face_measurements.csv\"\n",
    "count = 0\n",
    "\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"image\", \"face_width\", \"face_height\", \"width_to_height\", \"eye_spacing\"])\n",
    "\n",
    "    for filename in os.listdir(landmark_dir):\n",
    "        if filename.endswith(\".pts\"):\n",
    "            filepath = os.path.join(landmark_dir, filename)\n",
    "            try:\n",
    "                landmarks = parse_pts(filepath)\n",
    "                if len(landmarks) != 86:\n",
    "                    print(f\"⚠️ Skipped {filename} (not 86 points)\")\n",
    "                    continue\n",
    "                width, height, ratio, eye_spacing = compute_metrics(landmarks)\n",
    "                img_name = filename.replace(\".pts\", \".jpg\")\n",
    "                writer.writerow([img_name, width, height, ratio, eye_spacing])\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error processing {filename}: {str(e) or type(e).__name__}\")\n",
    "\n",
    "print(f\"✅ Processed {count} landmark files into {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1cd7c",
   "metadata": {},
   "source": [
    "take face_measurements.csv and make it a pandas dataframe with the beauty scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('face_measurements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b59fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f699a71",
   "metadata": {},
   "source": [
    "# Make recc logic\n",
    "\n",
    "rule based using ehrustics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_glasses(face_width, face_height, eye_spacing):\n",
    "    \"\"\"\n",
    "    Recommends glasses styles based on facial measurements.\n",
    "    \n",
    "    Parameters:\n",
    "        face_width (float): Distance between jaw corners\n",
    "        face_height (float): Distance from forehead to chin\n",
    "        eye_spacing (float): Distance between eye centers\n",
    "        \n",
    "    Returns:\n",
    "        List of (style, score) tuples, sorted by score descending\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "\n",
    "    width_to_height = face_width / face_height if face_height else 0\n",
    "\n",
    "    # Rule: Wide faces -> soften with round or oversized\n",
    "    if width_to_height > 1.5:\n",
    "        recommendations.append((\"Round\", 0.9))\n",
    "        recommendations.append((\"Oversized\", 0.8))\n",
    "\n",
    "    # Rule: Long/narrow faces -> add width with square or bold frames\n",
    "    if face_height > face_width * 1.3:\n",
    "        recommendations.append((\"Square\", 0.85))\n",
    "        recommendations.append((\"Cat-eye\", 0.75))\n",
    "\n",
    "    # Rule: Close-set eyes -> minimal bridge\n",
    "    if eye_spacing < face_width * 0.25:\n",
    "        recommendations.append((\"Rimless\", 0.8))\n",
    "\n",
    "    # Rule: Wide-set eyes -> bold bridge styles\n",
    "    if eye_spacing > face_width * 0.35:\n",
    "        recommendations.append((\"Rectangle\", 0.8))\n",
    "\n",
    "    # Rule: Average proportions → fallback recommendation\n",
    "    if not recommendations:\n",
    "        recommendations.append((\"Rectangle\", 0.7))\n",
    "        recommendations.append((\"Round\", 0.6))\n",
    "\n",
    "    # Sort by score descending\n",
    "    sorted_recs = sorted(recommendations, key=lambda x: -x[1])\n",
    "    return sorted_recs\n",
    "\n",
    "\n",
    "\n",
    "reccs = []\n",
    "for i in range(len(data)):\n",
    "    reccs.append(recommend_glasses(data.iloc[i].face_width, data.iloc[i].face_height, data.iloc[i].eye_spacing))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
